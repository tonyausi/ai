{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.12.2\n"
     ]
    }
   ],
   "source": [
    "! python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install --upgrade langchain-openai langchain-community\n",
    "%pip install --upgrade psycopg2-binary\n",
    "%pip install --upgrade tiktoken\n",
    "%pip install --upgrade ipywidgets\n",
    "%pip install --upgrade langchain.embeddings\n",
    "%pip install --upgrage langchain_openai\n",
    "%pip install --upgrade langchain_nomic\n",
    "%pip install --upgrade lm-studio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reset to the PostgresSQL database\n",
    "\n",
    "Connect to the database and reset using the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Postgres DB vector_store is reseted\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import nest_asyncio\n",
    "\n",
    "\n",
    "nest_asyncio.apply()  # https://pypi.org/project/nest-asyncio/\n",
    "\n",
    "try:\n",
    "    pg_pw = \"mysecretpassword\"\n",
    "    pg_db = \"vector_store\"\n",
    "    connection_string = f\"postgresql://postgres:{pg_pw}@localhost:5432\"\n",
    "    db_name = pg_db\n",
    "    conn = psycopg2.connect(connection_string)\n",
    "    conn.autocommit = True\n",
    "\n",
    "    with conn.cursor() as c:\n",
    "        c.execute(f\"DROP DATABASE {db_name} WITH (FORCE);\")\n",
    "        c.execute(f\"CREATE DATABASE {db_name};\")\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "    print(f\"Postgres DB '{pg_db}' is reseted\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I found that langchain seems not able to support local LM-Studio embedding model. I have tried 2 different approaches:\n",
    "1. Applying OpenAI from langchain_openai and using .embeddings method. It split out \"AttributeError: 'OpenAI' object has no attribute 'embeddings'\"\n",
    "2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "### Option 1\n",
    "################################\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "\n",
    "# Point to the local server\n",
    "client = OpenAI(base_url=\"http://localhost:1234/v1\",\n",
    "                model=\"lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF\",\n",
    "                temperature=0,\n",
    "                api_key=\"lm-studio\")\n",
    "\n",
    "\n",
    "def get_embedding(text, model=\"nomic-ai/nomic-embed-text-v1.5-GGUF\"):\n",
    "   \"\"\"\n",
    "   Get embeddings using LM Studio (Open AI API)\n",
    "   \"\"\" \n",
    "   text = text.replace(\"\\n\", \" \")\n",
    "   return client.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "\n",
    "\n",
    "embeddings = get_embedding(\"Once upon a time, there was a cat.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain_nomic import NomicEmbeddings\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "\"\"\"\n",
    "Get embeddings using OpenAIEmbedding from LlamaIndex\n",
    "\"\"\"\n",
    "\n",
    "# Initialize the LM-Studio embedding model\n",
    "embedding_model = OpenAIEmbeddings(\n",
    "    deployment=\"test\",\n",
    "    model=\"nomic-ai/nomic-embed-text-v1.5-GGUF\",\n",
    "    openai_api_base=\"http://localhost:1234/v1/embeddings\",\n",
    "    openai_api_key=\"lm-studio\",\n",
    ")\n",
    "text_embedding = embedding_model.embed_query(\"Once upon a time, there was a cat.\")\n",
    "print(text_embedding[:5])\n",
    "print(f\"Emedding length: {len(text_embedding)}\")\n",
    "vector_size = len(text_embedding)\n",
    "'''embedding_model = NomicEmbeddings(\n",
    "    nomic_api_key=\"lm-studio\", \n",
    "    api_base=\"http://localhost:1234/v1\", \n",
    "    model=\"nomic-ai/nomic-embed-text-v1.5-GGUF\",\n",
    "    inference_mode='local'\n",
    ")'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
